# -*- coding: utf-8 -*-
"""semlab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nmea4ds1x27E0JsmS7sA1vb5lVjuJrx_
"""

import pandas as pd
from sklearn.ensemble import AdaBoostClassifier, VotingClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier

df = pd.read_csv("/content/data.csv")

df.info()
print(df.iloc[0,-1])

df.describe()

df.drop('Unnamed: 32',inplace=True,axis=1)

df.drop('id',inplace=True,axis=1)
num=[]
cat=[]
nc=[]
for i,(name,ty) in enumerate(df.dtypes.items()):
  if ty in ['int64','float64']:
    num.append(name)
    nc.append(i)
  else:
    cat.append(name)



j=-1;o=0
for i in num:
  q=df[i].quantile([0.25,0.75])
  iqr=q[0.75]-q[0.25]
  j+=1
  for k in range(len(df)):
    if (df.iloc[k,nc[j]]>q[0.75]+iqr) or(df.iloc[k,nc[j]]<q[0.25]-iqr):
      o+=1
print(o)

le=LabelEncoder()
y=df['diagnosis'].values
x=df.drop('diagnosis',axis=1).values
y=le.fit_transform(y)
xtr,xte,ytr,yte=train_test_split(x,y,random_state=42)

ada=AdaBoostClassifier()
ada.fit(xtr,ytr)
trainpred=ada.predict(xtr)
testpred=ada.predict(xte)
a=accuracy_score(trainpred,ytr)
b=accuracy_score(testpred,yte)
print(a,b)

tre=DecisionTreeClassifier(max_depth=10)
logi=LogisticRegression(max_iter=100,solver='liblinear')
neigh=KNeighborsClassifier(n_neighbors=60)
models=[tre,logi,neigh]
models2=[tre,logi]

for i in models:
  i.fit(xtr,ytr)
  trainpred=i.predict(xtr)
  testpred=i.predict(xte)
  a=accuracy_score(trainpred,ytr)
  b=accuracy_score(testpred,yte)
  print(a,b)

for n_es in [25,50,100,200,300]:
  for i in models2:
    model=AdaBoostClassifier(estimator=i,n_estimators=n_es,random_state=8)
    model.fit(xtr,ytr)
    trainpred=model.predict(xtr)
    testpred=model.predict(xte)
    a=accuracy_score(trainpred,ytr)
    b=accuracy_score(testpred,yte)
    print(f'For {n_es} and {i}',a,b)

v=VotingClassifier(estimators=[('1',models[0]),('2',models[1]),('3',models[2])],voting="soft")
v.fit(xtr,ytr)
trainpred=v.predict(xtr)
testpred=v.predict(xte)
a=accuracy_score(trainpred,ytr)
b=accuracy_score(testpred,yte)
print(a,b)